{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ln52G_ho6vm"
      },
      "source": [
        "# Data preparation, exploration and sorting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LV0m5WpgwSFi"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bCE_pkoDm4s"
      },
      "source": [
        "# Downloading packages and loading libraries\n",
        "This section imports all the necessary libraries and modules required for the script to run. It includes libraries for data manipulation, visualization, machine learning models, image preprocessing, and model evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5mXaoaRpLbL"
      },
      "outputs": [],
      "source": [
        "! pip install tensorflow_addons\n",
        "! pip install visualkeras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7TlsqXwQA_E"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "import tensorflow as tf\n",
        "from random import randint\n",
        "from tensorflow import keras\n",
        "import tensorflow_addons as tfa\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Model\n",
        "from keras.utils import plot_model\n",
        "from tensorflow.keras import Sequential, Input\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.layers import Conv2D, Flatten\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import matthews_corrcoef as MCC\n",
        "from distutils.dir_util import copy_tree, remove_tree\n",
        "from sklearn.metrics import balanced_accuracy_score as BAS\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator as IDG\n",
        "from tensorflow.keras.layers import SeparableConv2D, BatchNormalization, MaxPool2D, GlobalAveragePooling2D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryZw7V1PFXbG"
      },
      "source": [
        "# Installing the Kaggle API client and setting up the Kaggle configuration file\n",
        "\n",
        "After running these commands, it is possible to use the Kaggle API client to interact with Kaggle datasets. `kaggle.json` file is created via Kaggle and uploaded manually to Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FYuvdTTZ9ta"
      },
      "outputs": [],
      "source": [
        "# Install the Kaggle API client package using pip\n",
        "! pip install kaggle\n",
        "# Create a directory named `.kaggle` in the user's home directory (`~`), which is where the Kaggle configuration file will be stored\n",
        "! mkdir ~/.kaggle\n",
        "# Copy the Kaggle API credentials file (`kaggle.json`) to the newly created `.kaggle` directory\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "# Change the permissions of the `kaggle.json` file to make it readable and writable only by the owner (the user), ensuring that the API credentials are secure\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Upw-2jxZEyPb"
      },
      "source": [
        "\n",
        "#Setting the random seed to the same value\n",
        "This ensures reproducibility of results when using random number generation functions, which is especially important in machine learning tasks where randomness is involved, such as weight initialization, data shuffling, or dropout. By setting the random seed, random numbers generated during different runs of the script remain the same, providing consistent and comparable results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1yHkjjmWqt2"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(5638)\n",
        "random.seed(5638)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-43RPKIGcCK"
      },
      "source": [
        "#Downloading the curated dataset from Kaggle\n",
        "\n",
        "This dataset is related to dementia and contains images categorized into three classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ne_ShfcqjTLw"
      },
      "outputs": [],
      "source": [
        "! kaggle datasets download -d zofiaknapiska/adni-selected-processed-brain-axial-t1-mri-jpeg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgEyMkn6Gqfe"
      },
      "source": [
        "#Unzipping and exploring the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2amyKPCk4Hd"
      },
      "outputs": [],
      "source": [
        "! unzip '/content/adni-selected-processed-brain-axial-t1-mri-jpeg.zip'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xJCfXxVqsrT"
      },
      "source": [
        "#Preparing the data for training and testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlMPLVx-HBp5"
      },
      "source": [
        "#Defining parameters for training a neural network model\n",
        "\n",
        "Setting parameters and configurations for image processing and neural network training. These parameters help in standardizing the input images and controlling the training process, ensuring consistency and efficiency."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7Piv_bflG9k"
      },
      "outputs": [],
      "source": [
        "# Define the number of epochs, which is the number of times the entire dataset will be passed forward and backward through the neural network during training\n",
        "EPOCHS = 50\n",
        "\n",
        "# Set the batch size, which determines the number of samples that will be propagated through the network at a time\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Define the size to which the images will be resized in pixels\n",
        "IMG_SIZE = 192\n",
        "\n",
        "#Store the image size as a list with two elements, both set to 192\n",
        "IMAGE_SIZE = [192, 192, 3]\n",
        "\n",
        "# Define the dimensions to which the images will be resized as a tuple\n",
        "DIM = (IMG_SIZE, IMG_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kSY_OjRrCLt"
      },
      "source": [
        "# Visualizing the distribution of labels in the training set\n",
        "The labels correspond to the different types of dementia in the training dataset. They provide insight into the balance or imbalance of classes, which is crucial for training a machine learning model effectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0QI84Xbl9x3"
      },
      "outputs": [],
      "source": [
        "# Path to the directory containing training images\n",
        "train_dir = Path('/content/archive/train')\n",
        "\n",
        "# Get filepaths and labels\n",
        "filepaths = list(train_dir.glob(r'**/*.jpg'))\n",
        "labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))\n",
        "\n",
        "filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n",
        "labels = pd.Series(labels, name='Label')\n",
        "\n",
        "# Concatenate filepaths and labels\n",
        "train_df = pd.concat([filepaths, labels], axis=1)\n",
        "\n",
        "# Shuffle the DataFrame and reset index\n",
        "train_df = train_df.sample(frac=1).reset_index(drop = True)\n",
        "\n",
        "# Split training data into train and validation sets\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.2, stratify=train_df['Label'], random_state=5638)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhs_yLFtrz35"
      },
      "source": [
        "# Visualizing the distribution of labels in the testing set\n",
        "The labels correspond to the different types of dementia in the testing dataset. They provide insight into the balance or imbalance of classes, which is crucial for testing a machine learning model effectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PzFRraOLmPl0"
      },
      "outputs": [],
      "source": [
        "# Path to the directory containing testing images\n",
        "test_dir = Path('/content/archive/test')\n",
        "\n",
        "# Get filepaths and labels\n",
        "filepaths = list(test_dir.glob(r'**/*.jpg'))\n",
        "labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))\n",
        "\n",
        "filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n",
        "labels = pd.Series(labels, name='Label')\n",
        "\n",
        "# Concatenate filepaths and labels\n",
        "test_df = pd.concat([filepaths, labels], axis=1)\n",
        "\n",
        "# Shuffle the DataFrame and reset index\n",
        "test_df = test_df.sample(frac=1).reset_index(drop = True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6), dpi=100)  # Set figure size and dpi\n",
        "plt.subplots_adjust(left=0.15, right=0.9, top=0.9, bottom=0.15)  # Adjust padding\n",
        "\n",
        "# Plot the grouped sizes as a horizontal bar plot\n",
        "ax = train_df.groupby('Label').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))\n",
        "\n",
        "# Set the title of the x-axis\n",
        "plt.xlabel('Counts')\n",
        "\n",
        "# Set the title of the plot\n",
        "plt.title('Training set - label distribution')\n",
        "\n",
        "# Remove the spines on the top and right sides of the plot\n",
        "plt.gca().spines[['top', 'right']].set_visible(False)\n",
        "\n",
        "# Add text annotations for each bar to display the counts\n",
        "for i in ax.patches:\n",
        "    ax.text(i.get_width() + 0.1, i.get_y() + 0.1, str(round(i.get_width())), fontsize=10, color='black')\n",
        "\n",
        "# Show the plot\n",
        "plt.savefig('train_set_label_distribution.png', bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 6), dpi=100)  # Set figure size and dpi\n",
        "plt.subplots_adjust(left=0.15, right=0.9, top=0.9, bottom=0.15)  # Adjust padding\n",
        "\n",
        "# Plot the grouped sizes as a horizontal bar plot\n",
        "cx = val_df.groupby('Label').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))\n",
        "\n",
        "# Set the title of the x-axis\n",
        "plt.xlabel('Counts')\n",
        "\n",
        "# Set the title of the plot\n",
        "plt.title('Validation set - label distribution')\n",
        "\n",
        "# Remove the spines on the top and right sides of the plot\n",
        "plt.gca().spines[['top', 'right']].set_visible(False)\n",
        "\n",
        "# Add text annotations for each bar to display the counts\n",
        "for i in cx.patches:\n",
        "    cx.text(i.get_width() + 0.1, i.get_y() + 0.1, str(round(i.get_width())), fontsize=10, color='black')\n",
        "\n",
        "# Show the plot\n",
        "plt.savefig('val_set_label_distribution.png', bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8, 6), dpi=100)  # Set figure size and dpi\n",
        "plt.subplots_adjust(left=0.15, right=0.9, top=0.9, bottom=0.15)  # Adjust padding\n",
        "\n",
        "# Plot the grouped sizes as a horizontal bar plot\n",
        "bx = test_df.groupby('Label').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))\n",
        "\n",
        "# Set the title of the x-axis\n",
        "plt.xlabel('Counts')\n",
        "\n",
        "# Set the title of the plot\n",
        "plt.title('Testing set - label distribution')\n",
        "\n",
        "# Remove the spines on the top and right sides of the plot\n",
        "plt.gca().spines[['top', 'right']].set_visible(False)\n",
        "\n",
        "# Add text annotations for each bar to display the counts\n",
        "for i in bx.patches:\n",
        "    bx.text(i.get_width() + 0.1, i.get_y() + 0.1, str(round(i.get_width())), fontsize=10, color='black')\n",
        "\n",
        "# Show the plot\n",
        "plt.savefig('test_set_label_distribution.png', bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "swikLFzacRE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSH8sGnAsi1M"
      },
      "source": [
        "#Utilizing `ImageDataGenerator` to prepare image data for training and testing\n",
        "Setting up data pipelines for training and testing deep learning models using Keras. Automating data preprocessing tasks such as scaling and batching, making it easier to work with large datasets efficiently."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtAs4_6Xmcxc"
      },
      "outputs": [],
      "source": [
        "train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale=1.0/255.0,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "test_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1.0/255.0)\n",
        "\n",
        "train_images = train_generator.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    x_col='Filepath',\n",
        "    y_col='Label',\n",
        "    target_size=(192,192),\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    seed = 5638,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_images = test_generator.flow_from_dataframe(\n",
        "    dataframe=val_df,\n",
        "    x_col='Filepath',\n",
        "    y_col='Label',\n",
        "    target_size=(192, 192),\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    seed=5638,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "test_images = test_generator.flow_from_dataframe(\n",
        "    dataframe=test_df,\n",
        "    x_col='Filepath',\n",
        "    y_col='Label',\n",
        "    target_size=(192, 192),\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    seed = 5638,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "CLASSES = list(test_images.class_indices.keys())\n",
        "num_classes = len(CLASSES)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZqmrZGTtzKL"
      },
      "source": [
        "#Calculating and visualizing the distribution of classes within both the training and testing datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4aiQZhuhmqGg"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "# Retrieve class indices mapping for both training and testing datasets\n",
        "train_class_indices = train_images.class_indices\n",
        "val_class_indices = val_images.class_indices\n",
        "test_class_indices = test_images.class_indices\n",
        "\n",
        "# Get the total number of classes present in the dataset\n",
        "num_classes = len(train_class_indices)\n",
        "\n",
        "# Initialize dictionaries to store counts of each class in the training and testing datasets\n",
        "train_class_counts = {class_name: 0 for class_name in train_class_indices}\n",
        "val_class_counts = {class_name: 0 for class_name in val_class_indices}\n",
        "test_class_counts = {class_name: 0 for class_name in test_class_indices}\n",
        "\n",
        "# Update counts for each class in the training set\n",
        "for label in train_images.labels:\n",
        "    class_name = CLASSES[label]\n",
        "    train_class_counts[class_name] += 1\n",
        "\n",
        "# Update counts for each class in the validation set\n",
        "for label in val_images.labels:\n",
        "    class_name = CLASSES[label]\n",
        "    val_class_counts[class_name] += 1\n",
        "\n",
        "# Update counts for each class in the testing set\n",
        "for label in test_images.labels:\n",
        "    class_name = CLASSES[label]\n",
        "    test_class_counts[class_name] += 1\n",
        "\n",
        "# Combine counts for both training and testing datasets\n",
        "combined_class_counts = {}\n",
        "for class_name in train_class_counts.keys():\n",
        "    combined_class_counts[class_name] = [train_class_counts[class_name], val_class_counts[class_name], test_class_counts[class_name]]\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "bar_width = 0.25\n",
        "index = np.arange(num_classes)\n",
        "\n",
        "# Plot bars for the training set\n",
        "train_bars = plt.bar(index, [count[0] for count in combined_class_counts.values()], bar_width,\n",
        "                     label='Train Set', color='b')\n",
        "\n",
        "# Plot bars for the validation set\n",
        "val_bars = plt.bar(index + bar_width, [count[1] for count in combined_class_counts.values()], bar_width,\n",
        "                   label='Validation Set', color='g')\n",
        "\n",
        "# Plot bars for the testing set\n",
        "test_bars = plt.bar(index + 2 * bar_width, [count[2] for count in combined_class_counts.values()], bar_width,\n",
        "                    label='Test Set', color='r')\n",
        "\n",
        "# Set labels and title for the plot\n",
        "plt.xlabel('Classes')\n",
        "plt.ylabel('Counts')\n",
        "plt.title('Class Distribution')\n",
        "plt.xticks(index + bar_width, combined_class_counts.keys(), rotation=45, ha='right')\n",
        "plt.legend()\n",
        "\n",
        "# Adjust layout and display the plot\n",
        "plt.tight_layout()\n",
        "plt.savefig('class_label_distribution.png', bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExKZpoiTuQ-L"
      },
      "source": [
        "#Displaying 20 sample images from the dataset along with their corresponding labels\n",
        "\n",
        "A visual representation of a subset of the dataset, allowing for a quick inspection of images and their associated labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9V3Hrk0AoEFu"
      },
      "outputs": [],
      "source": [
        "# Create a figure and a grid of subplots with 5 rows and 5 columns, totaling 20 subplots\n",
        "fig, axes = plt.subplots(nrows=5, ncols=5, figsize=(10, 10),\n",
        "                        subplot_kw={'xticks': [], 'yticks': []})\n",
        "\n",
        "# Iterate over each subplot in the grid\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    # Load and display the image corresponding to the filepath at index i in the DataFrame 'test_df'\n",
        "    ax.imshow(plt.imread(test_df.Filepath[i]), cmap='gray')\n",
        "    # Set the title of the subplot to the label of the image at index i in 'test_df'\n",
        "    ax.set_title(test_df.Label[i])\n",
        "\n",
        "# Adjust the layout to ensure proper spacing between subplots\n",
        "plt.tight_layout()\n",
        "\n",
        "# Display the plot containing the grid of images and labels\n",
        "plt.savefig('dataset_sample.png', bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCEXHw0Dw1Qf"
      },
      "source": [
        "#Working with the CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XwSKti4v_uG"
      },
      "source": [
        "#Defining a convolutional neural network (CNN) model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import class_weight\n",
        "\n",
        "# Compute class weights\n",
        "class_weights = class_weight.compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(train_df['Label']),\n",
        "    y=train_df['Label']\n",
        ")\n",
        "class_weights = {i: weight for i, weight in enumerate(class_weights)}"
      ],
      "metadata": {
        "id": "DktfU3tNdtp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RpJXwlmlOxTJ"
      },
      "outputs": [],
      "source": [
        "custom_model = Sequential([\n",
        "    Input(shape=(IMAGE_SIZE)),\n",
        "    Conv2D(16, 3, activation='relu', padding='same'),\n",
        "    Conv2D(16, 3, activation='relu', padding='same'),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(32, 3, activation='relu', padding='same'),\n",
        "    Conv2D(32, 3, activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(64, 3, activation='relu', padding='same'),\n",
        "    Conv2D(64, 3, activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(128, 3, activation='relu', padding='same'),\n",
        "    Conv2D(128, 3, activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(256, 3, activation='relu', padding='same'),\n",
        "    Conv2D(256, 3, activation='relu', padding='same', name = 'last_conv_layer'),\n",
        "    BatchNormalization(),\n",
        "    MaxPool2D(),\n",
        "    Flatten(),\n",
        "    Dropout(0.2),\n",
        "    Dense(512, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(128, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.7),\n",
        "    Dense(64, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "    Dense(3, activation='softmax')\n",
        "], name = \"custom_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I44Znjorkrv1"
      },
      "outputs": [],
      "source": [
        "from contextlib import redirect_stdout\n",
        "with open('modelsummary_model_custom.txt', 'w') as f:\n",
        "    with redirect_stdout(f):\n",
        "        custom_model.summary(show_trainable = True)\n",
        "\n",
        "# Display model summary\n",
        "custom_model.summary(show_trainable = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9uaBhVK1WyH"
      },
      "outputs": [],
      "source": [
        "import visualkeras\n",
        "\n",
        "font = ImageFont.truetype('arial.ttf', 12)\n",
        "visualkeras.layered_view(custom_model, to_file='model_custom_viskeras.png', legend=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YRCYcxyFz-ur"
      },
      "outputs": [],
      "source": [
        "# Calling plot_model method and displaying a model structure summary\n",
        "plot_model(custom_model, to_file='custom_model_structure.png', show_shapes=True, show_layer_names=True, rankdir='TB', expand_nested=False, dpi=100, show_layer_activations=True, show_trainable=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAjxho43xNSs"
      },
      "source": [
        "#Setting up the optimizer, defining evaluation metrics, and compiling the model for training\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HCsoKbaPPJBs"
      },
      "outputs": [],
      "source": [
        "# Define the Adam optimizer with a learning rate of 0.001 and assign it to the variable OPT\n",
        "OPT = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "\n",
        "# Define a list of evaluation metrics to be used during model training and validation\n",
        "METRICS = [\n",
        "    tf.keras.metrics.CategoricalAccuracy(name='acc'),  # Computes accuracy for multi-class classification\n",
        "    tf.keras.metrics.AUC(name='auc'),                  # Computes area under the ROC curve for binary classification\n",
        "    tfa.metrics.F1Score(num_classes=3)                 # Computes F1 score for multi-class classification with 3 classes\n",
        "]\n",
        "\n",
        "# Compile the model\n",
        "custom_model.compile(optimizer=OPT, loss=tf.losses.CategoricalCrossentropy(), metrics=METRICS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8_1mSqXyXNy"
      },
      "source": [
        "#Defining callbacks\n",
        "\n",
        "Essential for monitoring the training process, preventing overfitting, and saving the best model weights.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGVacZ-BPMjt"
      },
      "outputs": [],
      "source": [
        "# Configure early stopping, halting training when the validation loss stops decreasing\n",
        "earlystopping = EarlyStopping(\n",
        "    monitor='val_loss',    # Monitor the validation loss during training\n",
        "    mode='min',            # Stop training when the monitored quantity (val_loss) stops decreasing\n",
        "    patience=7,            # Number of epochs with no improvement after which training will be stopped\n",
        "    verbose=1              # Print messages about early stopping progress during training\n",
        ")\n",
        "\n",
        "# Define the filepath where the best model weights will be saved during training\n",
        "filepath = './model_custom_best_weights.keras'\n",
        "\n",
        "# Configure model checkpointing to save the best model weights based on validation loss\n",
        "checkpoint = ModelCheckpoint(\n",
        "    filepath,              # Filepath to save the best model weights\n",
        "    monitor='val_loss',    # Monitor the validation loss during training\n",
        "    mode='min',            # Save the weights when the monitored quantity (val_loss) achieves its minimum value\n",
        "    save_best_only=True,   # Save only the best model weights (with the lowest validation loss)\n",
        "    verbose=1              # Print messages about model checkpointing progress during training\n",
        ")\n",
        "\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
        "                              factor=0.2,\n",
        "                              patience=3,\n",
        "                              min_lr=1e-6)\n",
        "\n",
        "# Create a list of callbacks to be used during model training, including early stopping and model checkpointing\n",
        "callback_list = [earlystopping, checkpoint, reduce_lr]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03F1VfoM2yXK"
      },
      "source": [
        "#Training and Validating a Model\n",
        "\n",
        "Fitting the training data to a machine learning model and validating its performance using separate validation data. The code employs callbacks specified in `callback_list` to monitor and control the training process. The `epochs` parameter determines the number of times the entire training dataset is passed forward and backward through the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYh21H6BPOhT"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "custom_history = custom_model.fit(\n",
        "    train_images,\n",
        "    validation_data=val_images,\n",
        "    callbacks=callback_list,\n",
        "    epochs=EPOCHS,\n",
        "    class_weight=class_weights  # Add class weights to handle class imbalance\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efZqzBcE3QZW"
      },
      "source": [
        "#Monitoring Model Performance with Accuracy and Loss Plots\n",
        "\n",
        "Generating four plots to monitor the performance of a custom machine learning model during training and validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P73x6k9kP3nH"
      },
      "outputs": [],
      "source": [
        "# Create a figure and axes for the accuracy plot\n",
        "plt.figure(figsize=(8, 6))  # Set the size of the figure\n",
        "plt.grid(True, linestyle=':', linewidth=0.5, color='gray')  # Add a delicate grid in the background\n",
        "plt.plot(custom_history.history['acc'], linestyle='-', label='Training')  # Plot training accuracy without markers\n",
        "plt.plot(custom_history.history['val_acc'], linestyle='--', label='Validation')  # Plot validation accuracy without markers\n",
        "plt.title('Model Accuracy')  # Set title for the plot\n",
        "plt.ylabel('Accuracy')  # Label y-axis\n",
        "plt.xlabel('Epoch')  # Label x-axis\n",
        "plt.xticks(range(0, len(custom_history.history['acc'])+1, max(1, len(custom_history.history['acc'])//10)))  # Dynamic x-axis based on the number of epochs\n",
        "\n",
        "# Find and mark the best epoch for validation accuracy\n",
        "best_epoch_val_acc = custom_history.history['val_acc'].index(max(custom_history.history['val_acc']))\n",
        "plt.scatter(best_epoch_val_acc, max(custom_history.history['val_acc']), color='green', label=f'Best Epoch ({best_epoch_val_acc + 1})')\n",
        "\n",
        "plt.legend(loc='lower right')  # Add legend to indicate which line represents train and validation\n",
        "plt.tight_layout()  # Adjust layout to prevent overlapping of elements\n",
        "plt.savefig('acc.png')\n",
        "plt.show()  # Display the plot\n",
        "\n",
        "# Create a figure and axes for the loss plot\n",
        "plt.figure(figsize=(8, 6))  # Set the size of the figure\n",
        "plt.grid(True, linestyle=':', linewidth=0.5, color='gray')  # Add a delicate grid in the background\n",
        "plt.plot(custom_history.history['loss'], linestyle='-', label='Training')  # Plot training loss without markers\n",
        "plt.plot(custom_history.history['val_loss'], linestyle='--', label='Validation')  # Plot validation loss without markers\n",
        "plt.title('Model Loss')  # Set title for the plot\n",
        "plt.ylabel('Loss')  # Label y-axis\n",
        "plt.xlabel('Epoch')  # Label x-axis\n",
        "plt.xticks(range(0, len(custom_history.history['loss'])+1, max(1, len(custom_history.history['loss'])//10)))  # Dynamic x-axis based on the number of epochs\n",
        "\n",
        "# Find and mark the best epoch for validation loss\n",
        "best_epoch_val_loss = custom_history.history['val_loss'].index(min(custom_history.history['val_loss']))\n",
        "plt.scatter(best_epoch_val_loss, min(custom_history.history['val_loss']), color='green', label=f'Best Epoch ({best_epoch_val_loss + 1})')\n",
        "\n",
        "plt.legend(loc='upper right')  # Add legend to indicate which line represents train and validation\n",
        "plt.tight_layout()  # Adjust layout to prevent overlapping of elements\n",
        "plt.savefig('loss.png')\n",
        "plt.show()  # Display the plot\n",
        "\n",
        "# Create a figure and axes for the AUC plot\n",
        "plt.figure(figsize=(8, 6))  # Set the size of the figure\n",
        "plt.grid(True, linestyle=':', linewidth=0.5, color='gray')  # Add a delicate grid in the background\n",
        "plt.plot(custom_history.history['auc'], linestyle='-', label='Training')  # Plot training AUC without markers\n",
        "plt.plot(custom_history.history['val_auc'], linestyle='--', label='Validation')  # Plot validation AUC without markers\n",
        "plt.title('Model AUC')  # Set title for the plot\n",
        "plt.ylabel('AUC')  # Label y-axis\n",
        "plt.xlabel('Epoch')  # Label x-axis\n",
        "plt.xticks(range(0, len(custom_history.history['auc'])+1, max(1, len(custom_history.history['auc'])//10)))  # Dynamic x-axis based on the number of epochs\n",
        "\n",
        "# Find and mark the best epoch for validation AUC\n",
        "best_epoch_val_auc = custom_history.history['val_auc'].index(max(custom_history.history['val_auc']))\n",
        "plt.scatter(best_epoch_val_auc, max(custom_history.history['val_auc']), color='green', label=f'Best Epoch ({best_epoch_val_auc + 1})')\n",
        "\n",
        "plt.legend(loc='lower right')  # Add legend to indicate which line represents train and validation\n",
        "plt.tight_layout()  # Adjust layout to prevent overlapping of elements\n",
        "plt.savefig('auc.png')\n",
        "plt.show()  # Display the plot\n",
        "\n",
        "# Get F1 scores from the history\n",
        "f1_scores_train = custom_history.history['f1_score']\n",
        "f1_scores_val = custom_history.history['val_f1_score']\n",
        "\n",
        "# Create a figure and axes for the F1 score plot\n",
        "plt.figure(figsize=(8, 6))  # Set the size of the figure\n",
        "plt.grid(True, linestyle=':', linewidth=0.5, color='gray')  # Add a delicate grid in the background\n",
        "\n",
        "# Plot training F1 score with a solid line\n",
        "f1_scores_train_avg = np.mean(f1_scores_train, axis=1)\n",
        "plt.plot(f1_scores_train_avg, linestyle='-', label='Training')\n",
        "\n",
        "# Plot validation F1 score with a dashed line\n",
        "f1_scores_val_avg = np.mean(f1_scores_val, axis=1)\n",
        "plt.plot(f1_scores_val_avg, linestyle='--', label='Validation')\n",
        "\n",
        "# Find and mark the best epoch for validation F1 score\n",
        "best_epoch_val_f1 = np.argmax(f1_scores_val_avg)\n",
        "plt.scatter(best_epoch_val_f1, f1_scores_val_avg[best_epoch_val_f1], color='green', zorder=5, label=f'Best Epoch ({best_epoch_val_f1 + 1})')\n",
        "\n",
        "plt.title('Model F1 Score')  # Set title for the plot\n",
        "plt.ylabel('F1 Score')  # Label y-axis\n",
        "plt.xlabel('Epoch')  # Label x-axis\n",
        "plt.xticks(range(0, len(f1_scores_train_avg) + 1, max(1, len(f1_scores_train_avg) // 10)))  # Dynamic x-axis based on the number of epochs\n",
        "\n",
        "plt.legend(loc='lower right')  # Add legend to indicate which line represents train and validation\n",
        "plt.tight_layout()  # Adjust layout to prevent overlapping of elements\n",
        "plt.savefig('f1_score.png')\n",
        "plt.show()  # Display the plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNX6H4Yk6Bcb"
      },
      "source": [
        "#Evaluating Model Performance and Generating Classification Report\n",
        "\n",
        "The performance of a custom machine learning model is evaluated using the test dataset.\n",
        "\n",
        "First, the `evaluate` method is called on the model with the test images, providing evaluation scores. The accuracy of the model on the test data is then printed.\n",
        "\n",
        "Next, the model predicts labels for the test images using the `predict` method. The predicted labels are then processed using a `roundoff` function, which rounds off each predicted label array by setting non-maximum values to 0 and the maximum value to 1.\n",
        "\n",
        "After rounding off the predicted labels, the index of the maximum value along axis 1 is extracted to get the final predicted labels.\n",
        "\n",
        "Finally, a classification report is generated using the `classification_report` function from scikit-learn, comparing the predicted labels against the true labels in the test dataset. The classification report provides metrics such as precision, recall, and F1-score for each class, aiding in the evaluation of the model's performance across different classes."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/content/model_custom_best_weights.keras')"
      ],
      "metadata": {
        "id": "Q4m7c0xuWSi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5Z6yNPvQLlE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "model_path = '/content/model_custom_best_weights.keras'\n",
        "# Load the model\n",
        "loaded_model = load_model(model_path)\n",
        "\n",
        "# Evaluate the model on test data\n",
        "test_scores = loaded_model.evaluate(test_images)\n",
        "print(\"Testing Accuracy: %.2f%%\" % (test_scores[1] * 100))\n",
        "\n",
        "# Predict labels for test images\n",
        "pred_labels = loaded_model.predict(test_images)\n",
        "\n",
        "def roundoff(arr):\n",
        "    \"\"\"To round off according to the argmax of each predicted label array.\"\"\"\n",
        "    arr[np.argmax(arr)] = 1  # Set maximum value to 1\n",
        "    arr[arr != 1] = 0  # Set non-maximum values to 0\n",
        "    return arr\n",
        "\n",
        "for i in range(len(pred_labels)):\n",
        "    pred_labels[i] = roundoff(pred_labels[i])  # Round off the predicted labels\n",
        "\n",
        "pred = np.argmax(pred_labels, axis=1)  # Get the index of the maximum value along axis 1\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(test_images.classes, pred, target_names=CLASSES, zero_division=1))\n",
        "\n",
        "import sys\n",
        "# Save the original standard output\n",
        "original_stdout = sys.stdout\n",
        "\n",
        "# Open a file in write mode to save the information\n",
        "with open('loaded_model_evaluation_info.txt', 'w') as f:\n",
        "    # Redirect the standard output to the file\n",
        "    sys.stdout = f\n",
        "\n",
        "    # Evaluate the model on test data\n",
        "    test_scores = loaded_model.evaluate(test_images)\n",
        "    print(\"Testing Accuracy: %.2f%%\" % (test_scores[1] * 100))\n",
        "\n",
        "    # Predict labels for test images\n",
        "    pred_labels = loaded_model.predict(test_images)\n",
        "\n",
        "    for i in range(len(pred_labels)):\n",
        "        pred_labels[i] = roundoff(pred_labels[i])  # Round off the predicted labels\n",
        "\n",
        "    pred = np.argmax(pred_labels, axis=1)  # Get the index of the maximum value along axis 1\n",
        "\n",
        "    # Print classification report to the file\n",
        "    print(classification_report(test_images.classes, pred, target_names=CLASSES, zero_division=1))\n",
        "\n",
        "# Reset the standard output to the original value\n",
        "sys.stdout = original_stdout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eqx7Mw4Q6c6Q"
      },
      "source": [
        "#Visualizing Classification Performance with Confusion Matrix\n",
        "\n",
        "First, true and predicted labels are extracted from the test dataset and the model predictions, respectively. Then, the confusion matrix is computed using the `confusion_matrix` function from scikit-learn, which provides a summary of the model's predictions versus the actual labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-BGI7SNQTqv"
      },
      "outputs": [],
      "source": [
        "# Plot the confusion matrix to understand the classification in detail\n",
        "test_ls, pred_ls = test_images.classes, pred  # Get true and predicted labels\n",
        "conf_arr = confusion_matrix(test_ls, pred_ls)  # Compute confusion matrix\n",
        "\n",
        "# Compute percentages\n",
        "conf_arr_percent = conf_arr.astype('float') / conf_arr.sum(axis=1)[:, np.newaxis] * 100\n",
        "\n",
        "plt.figure(figsize=(8, 6), dpi=100)  # Set figure size and dpi\n",
        "plt.subplots_adjust(left=0.15, right=0.9, top=0.9, bottom=0.15)  # Adjust padding\n",
        "\n",
        "# Plot heatmap with annotations\n",
        "ax = sns.heatmap(conf_arr_percent, cmap='Blues', annot=True, fmt='.1f', cbar=True, xticklabels=CLASSES, yticklabels=CLASSES)\n",
        "\n",
        "for t in ax.texts:\n",
        "    t.set_text(t.get_text() + ' %')\n",
        "\n",
        "plt.title('Alzheimer\\'s Disease Diagnosis')  # Set title for the plot\n",
        "plt.xlabel('Predicted Labels')  # Set label for x-axis\n",
        "plt.ylabel('True Labels')  # Set label for y-axis\n",
        "plt.savefig('confusion_matrix_loaded_model.png', bbox_inches='tight')  # Save the plot with tight bounding box\n",
        "plt.show()  # Display the plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqkkPJAR9yMj"
      },
      "source": [
        "#Analyzing Model Performance with ROC Curve and Thresholds\n",
        "\n",
        "Analysis of model performance using Receiver Operating Characteristic (ROC) curves by incorporating different classification thresholds.\n",
        "\n",
        "After converting true labels into a binary format, ROC curves and areas under the curve (AUC) are computed for each class. Additionally, the true positive rate (TPR) and false positive rate (FPR) are calculated for various classification thresholds.\n",
        "\n",
        "The micro-average ROC curve and AUC are derived by aggregating TPR and FPR across all classes, while the macro-average ROC curve and AUC represent the average performance across all classes."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import roc_curve, auc, classification_report\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "# Evaluate the model on test data\n",
        "test_scores = loaded_model.evaluate(test_images)\n",
        "print(\"Testing Accuracy: %.2f%%\" % (test_scores[1] * 100))\n",
        "\n",
        "# Predict probabilities for test images\n",
        "pred_labels = loaded_model.predict(test_images)\n",
        "\n",
        "# Convert labels to binary format where each class is represented by a binary vector\n",
        "y_true = label_binarize(test_images.classes, classes=range(len(CLASSES)))  # CLASSES is the list of class names\n",
        "n_classes = y_true.shape[1]\n",
        "\n",
        "# Compute ROC curve and ROC area for each class\n",
        "fpr = dict()  # False Positive Rate\n",
        "tpr = dict()  # True Positive Rate\n",
        "roc_auc = dict()  # Area under ROC curve\n",
        "\n",
        "# Thresholds for which to compute ROC\n",
        "thresholds = np.linspace(0, 1, 100)  # 100 thresholds between 0 and 1\n",
        "tpr_values = np.zeros((n_classes, len(thresholds)))\n",
        "fpr_values = np.zeros((n_classes, len(thresholds)))\n",
        "\n",
        "# Iterate over each class to compute ROC curve and area\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_true[:, i], pred_labels[:, i])  # Compute FPR, TPR, thresholds\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])  # Compute area under ROC curve\n",
        "\n",
        "    # Compute TPR and FPR for different thresholds\n",
        "    for j, threshold in enumerate(thresholds):\n",
        "        tp = np.sum((pred_labels[:, i] >= threshold) & (y_true[:, i] == 1))\n",
        "        fp = np.sum((pred_labels[:, i] >= threshold) & (y_true[:, i] == 0))\n",
        "        tn = np.sum((pred_labels[:, i] < threshold) & (y_true[:, i] == 0))\n",
        "        fn = np.sum((pred_labels[:, i] < threshold) & (y_true[:, i] == 1))\n",
        "\n",
        "        tpr_values[i, j] = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        fpr_values[i, j] = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
        "\n",
        "# Compute micro-average ROC curve and ROC area\n",
        "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))  # Obtain all unique FPR values\n",
        "mean_tpr = np.zeros_like(all_fpr)  # Initialize mean TPR\n",
        "for i in range(n_classes):\n",
        "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])  # Interpolate TPR values\n",
        "mean_tpr /= n_classes  # Calculate mean TPR\n",
        "fpr[\"micro\"] = all_fpr\n",
        "tpr[\"micro\"] = mean_tpr\n",
        "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])  # Compute area under micro-average ROC curve\n",
        "\n",
        "# Compute macro-average ROC curve and ROC area\n",
        "roc_auc_macro = auc(fpr[\"micro\"], tpr[\"micro\"])  # Compute area under macro-average ROC curve\n",
        "\n",
        "# Plot ROC curve for each class\n",
        "lw = 2  # Adjust line width if needed\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "colors = ['aqua', 'darkorange', 'cornflowerblue']  # Adjust colors if needed\n",
        "for i, color in zip(range(n_classes), colors):\n",
        "    plt.step(fpr_values[i], tpr_values[i], color=color, lw=lw, where='post',\n",
        "             label='ROC curve of class {0} (area = {1:0.3f})'.format(CLASSES[i], roc_auc[i]))\n",
        "\n",
        "# Plot micro-average ROC curve\n",
        "plt.plot(fpr[\"micro\"], tpr[\"micro\"], color='deeppink', linestyle=':', linewidth=4,\n",
        "         label='Micro-average ROC curve (area = {0:0.3f})'.format(roc_auc[\"micro\"]))\n",
        "\n",
        "# Plot macro-average ROC curve\n",
        "plt.plot(fpr[\"micro\"], tpr[\"micro\"], color='navy', linestyle='--', linewidth=4,\n",
        "         label='Macro-average ROC curve (area = {0:0.3f})'.format(roc_auc_macro))\n",
        "\n",
        "# Plot points for different thresholds\n",
        "for i, color in zip(range(n_classes), colors):\n",
        "    for j, threshold in enumerate(thresholds[::10]):\n",
        "        plt.scatter(fpr_values[i, j*10], tpr_values[i, j*10], color=color, s=10)\n",
        "\n",
        "# Add random guess line\n",
        "plt.plot([0, 1], [0, 1], color='gray', lw=lw, linestyle='--')\n",
        "\n",
        "# Set plot properties\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve with Thresholds')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True, linestyle=':', linewidth=0.5, color='gray')  # Add a delicate grid in the background\n",
        "# Save the figure as a .png file\n",
        "plt.savefig('roc_curve_loaded_model_new.png')\n",
        "plt.show()\n",
        "\n",
        "# Print classification report\n",
        "pred = np.argmax(pred_labels, axis=1)  # Get the index of the maximum value along the axis 1\n",
        "print(classification_report(test_images.classes, pred, target_names=CLASSES))\n",
        "\n",
        "# # Save the evaluation and classification report to a file\n",
        "import sys\n",
        "\n",
        "# # Save the original standard output\n",
        "original_stdout = sys.stdout\n",
        "\n",
        "# # Open a file in write mode to save the information\n",
        "with open('loaded_model_evaluation_info.txt', 'w') as f:\n",
        "  # Redirect the standard output to the file\n",
        "  sys.stdout = f\n",
        "  # Evaluate the model on test data\n",
        "  test_scores = loaded_model.evaluate(test_images)\n",
        "  print(\"Testing Accuracy: %.2f%%\" % (test_scores[1] * 100))  # Print the testing accuracy\n",
        "\n",
        "  # Print classification report to the file\n",
        "  print(classification_report(test_images.classes, pred, target_names=CLASSES))\n",
        "\n",
        "  # Reset the standard output to the original value\n",
        "  sys.stdout = original_stdout"
      ],
      "metadata": {
        "id": "TOylqErhUOxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Misclassifications for each class"
      ],
      "metadata": {
        "id": "TU3ZxUx7W7ag"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZBFE_Xda8pl"
      },
      "outputs": [],
      "source": [
        "# Initialize misclassifications for each class\n",
        "misclassifications = np.zeros(len(CLASSES), dtype=int)\n",
        "\n",
        "# Initialize total instances for each class\n",
        "total_instances = np.zeros(len(CLASSES), dtype=int)\n",
        "\n",
        "# Iterate over each instance in the test set\n",
        "for true_label, pred_label in zip(test_ls, pred_ls):\n",
        "    # Increment total instances count for the true label's class\n",
        "    total_instances[true_label] += 1\n",
        "    # If the true label and predicted label don't match, increment misclassification count for the true label's class\n",
        "    if true_label != pred_label:\n",
        "        misclassifications[true_label] += 1\n",
        "\n",
        "# Calculate misclassifications as percentages\n",
        "misclassifications_percentage = (misclassifications / total_instances) * 100\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 6))  # Set figure size\n",
        "plt.subplots_adjust(left=0.15, right=0.9, top=0.9, bottom=0.15)  # Adjust padding\n",
        "\n",
        "# Plot the bar chart\n",
        "bars = plt.bar(CLASSES, misclassifications_percentage, color='skyblue')\n",
        "plt.title('Misclassifications on Test Set by Class')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Misclassifications Percentage')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(axis='y', linestyle=':', linewidth=0.5, color='gray')\n",
        "\n",
        "# Annotate each bar with its percentage value\n",
        "for bar, percentage in zip(bars, misclassifications_percentage):\n",
        "    height = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width() / 2, height, f'{percentage:.2f}%', ha='center', va='bottom')\n",
        "\n",
        "plt.savefig('missclass_loaded_model.png', bbox_inches='tight')  # Save the plot with tight bounding box\n",
        "plt.show()  # Display the plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x92o3O4BGfkK"
      },
      "source": [
        "#Printing Additional Classification Metrics\n",
        "\n",
        "1. **Balanced Accuracy Score (BAS)** - a metric that provides a balanced measure of classification performance, particularly useful for imbalanced datasets. It considers both the sensitivity (true positive rate) and specificity (true negative rate) of the model's predictions.\n",
        "\n",
        "2. **Matthew's Correlation Coefficient (MCC)** - a metric that measures the quality of binary classifications, taking into account both true and false positives and negatives. It ranges from -1 to 1, where 1 indicates perfect predictions, 0 indicates random predictions, and -1 indicates complete disagreement between predictions and true labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RmpD3TmEQiUq"
      },
      "outputs": [],
      "source": [
        "# Open a text file in write mode\n",
        "with open('classification_metrics_loaded_model.txt', 'w') as f:\n",
        "    # Write Balanced Accuracy Score (BAS) to the file\n",
        "    f.write(\"Balanced Accuracy Score: {} %\\n\".format(round(BAS(test_ls, pred_ls) * 100, 2)))\n",
        "\n",
        "    # Write Matthew's Correlation Coefficient (MCC) to the file\n",
        "    f.write(\"Matthew's Correlation Coefficient: {} %\\n\".format(round(MCC(test_ls, pred_ls) * 100, 2)))\n",
        "\n",
        "# Print a message indicating that the metrics have been saved\n",
        "print(\"Classification metrics have been saved to 'classification_metrics_loaded_model.txt'.\")\n",
        "\n",
        "# Printing some other classification metrics\n",
        "\n",
        "# Compute BAS and format the output as a percentage rounded to two decimal places.\n",
        "print(\"Balanced Accuracy Score: {} %\".format(round(BAS(test_ls, pred_ls) * 100, 2)))\n",
        "\n",
        "# Compute MCC and format the output as a percentage rounded to two decimal places.\n",
        "print(\"Matthew's Correlation Coefficient: {} %\".format(round(MCC(test_ls, pred_ls) * 100, 2)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3d0Md4kG0Z-"
      },
      "source": [
        "#Saving Custom CNN Model\n",
        "\n",
        "Saving a custom Convolutional Neural Network (CNN) model along with its performance score in the filename. The model is saved in the Keras HDF5 format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fApQ3gu1QniY"
      },
      "outputs": [],
      "source": [
        "# Save the custom CNN model\n",
        "custom_model.save('custom_cnn.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_b2yhEsHF6d"
      },
      "source": [
        "#Generating and Visualizing Gradient-weighted Class Activation Mapping (Grad-CAM)\n",
        "\n",
        "Functions to generate and visualize Gradient-weighted Class Activation Mapping (Grad-CAM) for interpreting the predictions made by a convolutional neural network (CNN) model.\n",
        "\n",
        "1. **`make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None)`:** This function computes the Grad-CAM heatmap for a given input image array, CNN model, and the name of the last convolutional layer. It calculates the gradient of the top predicted class with respect to the activations of the last convolutional layer, and then generates the heatmap by weighting the importance of each feature map channel. The heatmap is normalized between 0 and 1.\n",
        "\n",
        "2. **`save_and_display_gradcam(img_path, heatmap, cam_path=\"cam.jpg\", alpha=0.4)`:** This function loads the image, rescales the heatmap, and colorizes it using the jet colormap. It then superimposes the heatmap on the original image with a specified transparency level (`alpha`) and saves the resulting image. Finally, it returns the path of the saved image.\n",
        "\n",
        "This code enables the visualization of which parts of an input image contribute most to the model's prediction, aiding in model interpretation and understanding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUXtUpCBJl-6"
      },
      "outputs": [],
      "source": [
        "import matplotlib.cm as cm\n",
        "\n",
        "def get_img_array(img_path, size):\n",
        "    # Load the image from the given path and resize it to the specified size\n",
        "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=size)\n",
        "    # Convert the image to a numpy array\n",
        "    array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    # Add a batch dimension to the array\n",
        "    array = np.expand_dims(array, axis=0)\n",
        "    return array\n",
        "\n",
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
        "    # Create a new model that maps the input image to the activations of the last convolutional layer as well as the output predictions\n",
        "    grad_model = tf.keras.models.Model([model.inputs], [model.get_layer(last_conv_layer_name).output, model.output])\n",
        "\n",
        "    # Compute the gradient of the top predicted class for the input image with respect to the activations of the last convolutional layer\n",
        "    with tf.GradientTape() as tape:\n",
        "        last_conv_layer_output, preds = grad_model(img_array)\n",
        "        if pred_index is None:\n",
        "            pred_index = tf.argmax(preds[0])\n",
        "        class_channel = preds[:, pred_index]\n",
        "\n",
        "    # Compute the gradient of the output neuron with respect to the output feature map of the last convolutional layer\n",
        "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
        "\n",
        "    # Compute the mean intensity of the gradient over each feature map channel\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    # Multiply each channel in the feature map array by its importance and sum all channels to obtain the heatmap\n",
        "    last_conv_layer_output = last_conv_layer_output[0]\n",
        "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "\n",
        "    # Normalize the heatmap between 0 and 1\n",
        "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
        "    return heatmap.numpy()\n",
        "\n",
        "def save_and_display_gradcam(img_path, heatmap, cam_path=\"cam.jpg\", alpha=0.75):\n",
        "    # Load the original image\n",
        "    img = tf.keras.preprocessing.image.load_img(img_path)\n",
        "    img = tf.keras.preprocessing.image.img_to_array(img)\n",
        "\n",
        "    # Rescale heatmap to a range 0-255\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "\n",
        "    # Use jet colormap to colorize heatmap\n",
        "    jet = plt.get_cmap(\"jet\")\n",
        "\n",
        "    # Use RGB values of the colormap\n",
        "    jet_colors = jet(np.arange(256))[:, :3]\n",
        "    jet_heatmap = jet_colors[heatmap]\n",
        "\n",
        "    # Create an image with RGB colorized heatmap\n",
        "    jet_heatmap = tf.keras.preprocessing.image.array_to_img(jet_heatmap)\n",
        "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
        "    jet_heatmap = tf.keras.preprocessing.image.img_to_array(jet_heatmap)\n",
        "\n",
        "    # Superimpose the heatmap on original image\n",
        "    superimposed_img = jet_heatmap * alpha + img\n",
        "    superimposed_img = tf.keras.preprocessing.image.array_to_img(superimposed_img)\n",
        "\n",
        "    # Save the superimposed image\n",
        "    superimposed_img.save(cam_path)\n",
        "\n",
        "    # Return the path of the saved image\n",
        "    return cam_path\n",
        "\n",
        "# Define the size of the images\n",
        "img_size = IMAGE_SIZE\n",
        "\n",
        "# Remove the softmax activation from the last layer of the model\n",
        "custom_model.layers[-1].activation = None\n",
        "\n",
        "# Name of the last convolutional layer\n",
        "last_conv_layer_name = \"last_conv_layer\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMN5rpEaHP9M"
      },
      "source": [
        "#Making Predictions and Mapping Labels\n",
        "\n",
        "Performing predictions on the test images using a custom CNN model. After obtaining the predicted labels, it rounds off each label array to assign a binary classification. Then, it maps the numerical label indices to their corresponding class names."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5SEvzZpDLBIh"
      },
      "outputs": [],
      "source": [
        "# Perform predictions on the test images using the custom model\n",
        "pred_labels = custom_model.predict(test_images)\n",
        "\n",
        "def roundoff(arr):\n",
        "    \"\"\"Round off each array according to the index of its maximum value.\"\"\"\n",
        "    # Set all elements to 0 except for the maximum value, which is set to 1\n",
        "    arr[np.argwhere(arr != arr.max())] = 0\n",
        "    arr[np.argwhere(arr == arr.max())] = 1\n",
        "    return arr\n",
        "\n",
        "# Iterate over each predicted label array and round off the values\n",
        "for labels in pred_labels:\n",
        "    labels = roundoff(labels)\n",
        "\n",
        "# Obtain the index of the maximum value in each predicted label array\n",
        "pred = np.argmax(pred_labels,axis=1)\n",
        "\n",
        "# Map the numerical label indices to their respective class names\n",
        "labels = (test_images.class_indices)\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "pred = [labels[k] for k in pred]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M59Ihyn9Hclw"
      },
      "source": [
        "#Visualizing Neural Network Attention with Grad-CAM Heatmaps\n",
        "\n",
        "Generating and displaying Grad-CAM heatmaps superimposed on original images to visualize the parts of the pictures that a neural network focuses on when classifying them. Grad-CAM highlights the regions of an image that are most influential in the model's decision-making process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5RwOREt-LGtD"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the function to display images and Grad-CAM heatmaps neatly\n",
        "def display_images_with_heatmaps(test_df, pred, img_size, custom_model, last_conv_layer_name):\n",
        "    # Create a grid of subplots to display images and their heatmaps\n",
        "    fig, axes = plt.subplots(nrows=4, ncols=4, figsize=(12, 12), subplot_kw={'xticks': [], 'yticks': []})\n",
        "\n",
        "    # Iterate over each subplot and corresponding image\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        # Get the file path of the image\n",
        "        img_path = test_df.Filepath.iloc[i+164]\n",
        "        # Load the image and convert it to an array\n",
        "        img_array = get_img_array(img_path, size=img_size)\n",
        "        # Generate the Grad-CAM heatmap for the image\n",
        "        heatmap = make_gradcam_heatmap(img_array, custom_model, last_conv_layer_name)\n",
        "        # Save and display the Grad-CAM heatmap superimposed on the original image\n",
        "        cam_path = save_and_display_gradcam(img_path, heatmap)\n",
        "        # Display the image with its Grad-CAM heatmap as a subplot\n",
        "        img = plt.imread(cam_path)\n",
        "        ax.imshow(img, cmap='jet')\n",
        "\n",
        "        # Display ground truth, predicted label, and percentage\n",
        "        ground_truth = test_df.Label.iloc[i]\n",
        "        predicted_label = pred[i]\n",
        "\n",
        "        # Set title with smaller font size for neatness\n",
        "        ax.set_title(f\"Ground truth: {ground_truth}\\nPredicted label: {predicted_label}\", fontsize=8)\n",
        "\n",
        "    # Adjust layout and add colorbar spanning full length\n",
        "    plt.tight_layout()\n",
        "    cbar_ax = fig.add_axes([1, 0.1, 0.02, 0.8])  # Define colorbar axis (moved further to the right)\n",
        "    plt.colorbar(ax.images[0], cax=cbar_ax)  # Add colorbar\n",
        "\n",
        "    # Save and display the plot\n",
        "    plt.savefig(\"grad_cam.jpg\", bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "# Call the function to display images with heatmaps\n",
        "display_images_with_heatmaps(test_df, pred, img_size, custom_model, last_conv_layer_name)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}